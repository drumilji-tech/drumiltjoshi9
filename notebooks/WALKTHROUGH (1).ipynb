{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Performance and Reliability Data Sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleet 125: Processing WHE...\n",
      "Fleet 391: Calculating Power Curves for WHE\n",
      "[WindFarm 496] processing severity WHE, Xfmr_Winding1_Temp...\n",
      "[WindFarm 496] processing severity WHE, Xfrm_Aux_Temp...\n",
      "[WindFarm 496] processing severity WHE, blade_pitch_a...\n",
      "[WindFarm 496] processing severity WHE, blade_pitch_b...\n",
      "[WindFarm 496] processing severity WHE, blade_pitch_c...\n",
      "[WindFarm 496] processing severity WHE, Ctrl_Gnd_Temp...\n",
      "[WindFarm 496] processing severity WHE, Ctrl_Hub_Temp...\n",
      "[WindFarm 496] processing severity WHE, Ctrl_Top_Temp...\n",
      "[WindFarm 496] processing severity WHE, Ctrl_VCP_Temp...\n",
      "[WindFarm 496] processing severity WHE, Nacl_AD_ADj_Wind_Speed...\n",
      "[WindFarm 496] processing severity WHE, expected_power...\n",
      "[WindFarm 496] processing severity WHE, Gbx_CoolingWater_Temp...\n",
      "[WindFarm 496] processing severity WHE, Gbx_Oil_Temp...\n",
      "[WindFarm 496] processing severity WHE, Main_Brg_Temp...\n",
      "[WindFarm 496] processing severity WHE, Gen_Brg_DE_Temp...\n",
      "[WindFarm 496] processing severity WHE, Gen_Brg_NDE_Temp...\n",
      "[WindFarm 496] processing severity WHE, Gen_CoolingFluid_Temp...\n",
      "[WindFarm 496] processing severity WHE, Gen_Windings_PhaseA_Temp...\n",
      "[WindFarm 496] processing severity WHE, Gen_Windings_PhaseB_Temp...\n",
      "[WindFarm 496] processing severity WHE, Gen_Windings_PhaseC_Temp...\n",
      "[WindFarm 496] processing severity WHE, gen_speed...\n",
      "[WindFarm 496] processing severity WHE, Gbx_Brg_HighSpd_Temp...\n",
      "[WindFarm 496] processing severity WHE, HPU_Oil_Temp...\n",
      "[WindFarm 496] processing severity WHE, Gbx_Brg_IntrSpd_NDE_Temp...\n",
      "[WindFarm 496] processing severity WHE, Gbx_Brg_IntrSpd_DE_Temp...\n",
      "[WindFarm 496] processing severity WHE, active_power...\n",
      "[WindFarm 496] processing severity WHE, Xfrm_MV_CorePhaseA_Temp...\n",
      "[WindFarm 496] processing severity WHE, Xfrm_MV_CorePhaseB_Temp...\n",
      "[WindFarm 496] processing severity WHE, Xfrm_MV_CorePhaseC_Temp...\n",
      "[WindFarm 496] processing severity WHE, Xfrm_MV_PhaseA_Temp...\n",
      "[WindFarm 496] processing severity WHE, Nacelle_Temp...\n",
      "[WindFarm 496] processing severity WHE, Hub_Temp...\n",
      "[WindFarm 496] processing severity WHE, Nacl_Wind_Dir...\n",
      "[WindFarm 496] processing severity WHE, Yaw_Position...\n",
      "[WindFarm 496] processing severity WHE, Lost_Energy...\n",
      "WHE-T023 has 37.75 recovery and is being removed from results\n",
      "WHE-T027 has 37.03 recovery and is being removed from results\n",
      "WHE-T022 has 37.72 recovery and is being removed from results\n",
      "WHE-T026 has 37.53 recovery and is being removed from results\n",
      "WHE-T028 has 30.24 recovery and is being removed from results\n",
      "WHE-T029 has 37.05 recovery and is being removed from results\n",
      "WHE-T024 has 38.75 recovery and is being removed from results\n",
      "WHE-T025 has 37.87 recovery and is being removed from results\n",
      "[WindFarm 496] processing severity WHE, Yaw_Error...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd \n",
    "sys.path.append('..')\n",
    "from Model.Fleet import Fleet\n",
    "\n",
    "avg_path = '../southernoperations/AIID/AVG'\n",
    "compressed_path = '../southernoperations/AIID/CMP'\n",
    "yaw_path = '../southernoperations/AIID/YAW'\n",
    "oem_powercurves_path = '../assets/data/power_curves/all_power_curves.csv'\n",
    "\n",
    "fleet = Fleet(avg_dir=avg_path,cmp_dir=compressed_path, yaw_dir=yaw_path, oem_powercurves_path=oem_powercurves_path, single_plant=\"WHE\")\n",
    "\n",
    "powercurves = fleet.get_powercurves()\n",
    "powercurve_distributions = fleet.get_powercurve_distributions()\n",
    "daily_severity_scores = fleet.daily_severity_scores\n",
    "daily_severity_scores.columns = [x.replace(\"-EFFICIENCY\",\"-SEVERITY\") for x in daily_severity_scores.columns]\n",
    "daily_efficiencies =fleet.get_daily_efficiency()\n",
    "daily_lost_energy = fleet.get_daily_lost_energy()\n",
    "daily_lost_revenue = fleet.get_daily_lost_revenue()\n",
    "daily_means = fleet.get_daily_mean()\n",
    "daily_severity_scores = pd.concat([daily_severity_scores,daily_efficiencies,daily_lost_energy,daily_lost_revenue,daily_means], axis=1)\n",
    "\n",
    "daily_severity_scores.to_csv('../southernoperations/AIID/fleet_daily_severity_scores_stage.csv')\n",
    "powercurves.to_csv('../southernoperations/AIID/power_curve.csv')\n",
    "powercurve_distributions.to_csv('../southernoperations/AIID/power_curve_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Fleet Output\n",
    "This finalizes the processed data for use in the UI performance and reliability area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "treemap_data = pd.read_csv('../southernoperations/AIID/fleet_daily_severity_scores_stage.csv', index_col=[0], parse_dates = [0])\n",
    "try:\n",
    "    treemap_data = treemap_data[~treemap_data.index.to_series().str.match(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}')]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "treemap_data.index =pd.to_datetime(treemap_data.index)\n",
    "\n",
    "type_func = lambda x: '-'.join(x.split('-')[2:])\n",
    "col_suffixes = sorted(list(set([type_func(x) for x in treemap_data.columns])))\n",
    "\n",
    "temp_treemap_data= treemap_data[[x for x in treemap_data.columns if not any(y in x for y in ['KW','SIMPLE-EFFICIENCY'])]]\n",
    "\n",
    "temp_treemap_data.to_csv('../southernoperations/AIID/treemap_data.csv')\n",
    "\n",
    "efficiency_treemap = treemap_data[[x for x in treemap_data.columns if any(y in type_func(x) or y.endswith('_mean') for y in ['KW',\n",
    "                                                                                           'EFFICIENCY',\n",
    "                                                                                           'SEVERITY',\n",
    "                                                                                           'LOST-ENERGY',\n",
    "                                                                                           'LOST-REVENUE'])]]\n",
    "efficiency_treemap.to_csv('../southernoperations/AIID/treemap_data_simple_efficiency.csv')\n",
    "\n",
    "yaw_error_treemap_data = treemap_data[[x for x in treemap_data.columns if any(y in x for y in ['YAW-ERROR'])]]\n",
    "yaw_error_treemap_data.to_csv('../southernoperations/AIID/radial_yaw_error.csv')\n",
    "\n",
    "print(\"Data output to southernoperations/AIID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Fault Analysis Data Sets\n",
    "\n",
    "Processes raw 10 minute average and compressed fault code data into data ready to be consumed  by the UI in the fault analysis area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('..')\n",
    "from Model.Fault import FaultAnalysis\n",
    "\n",
    "projects = [\n",
    "            # 'BR2', \n",
    "            # 'BTH', \n",
    "            # 'CFW', \n",
    "            # 'DHW', \n",
    "            # 'GNT', \n",
    "            # 'GNP', \n",
    "            # 'GSW', \n",
    "            # 'KAY', \n",
    "            'PDK', \n",
    "            #  'RDG', \n",
    "            #  'SFK', \n",
    "            #  'SKO', \n",
    "            #  'TBF', \n",
    "            #  'WAK', \n",
    "            #  'WHE'\n",
    "            ]\n",
    "\n",
    "fault_analysis_objects = {}\n",
    "\n",
    "for project in projects:\n",
    "    \n",
    "    fault_data_path = f\"../southernoperations/AIID/CMP/{project}.csv\"\n",
    "    \n",
    "    avg_data_path = f\"../southernoperations/AIID/AVG/{project}_concat.csv\"\n",
    "    \n",
    "    print('Processing', project)\n",
    "    \n",
    "    cmp_data = pd.read_csv(fault_data_path, low_memory=False)\n",
    "    avg_data = pd.read_csv(avg_data_path, index_col=[0], parse_dates=[0])\n",
    "\n",
    "    downtime = FaultAnalysis(project=project, cmp_data=cmp_data, avg_data=avg_data)\n",
    "\n",
    "    downtime_data = downtime.reshaped_data\n",
    "    \n",
    "    #put each object in memory for use after run \n",
    "    fault_analysis_objects[project] = downtime\n",
    "    output_data = downtime_data.loc[downtime_data['StartDateTime'] > '8/1/2023'].dropna()\n",
    "    output_data.to_csv(f'../southernoperations/AIID/Processed Faults/{project}_downtime_lost_energy.csv', index=False)\n",
    "\n",
    "    # daily file output\n",
    "    daily_data = downtime.daily_downtime()\n",
    "    daily_data['FaultCount'] = downtime.daily_fault_count()[\"FaultCount\"]\n",
    "    daily_data['LostEnergy'] = downtime.daily_lost_energy()['LostEnergy']\n",
    "    daily_data['LostRevenue'] = downtime.daily_lost_revenue()['LostRevenue']\n",
    "\n",
    "    daily_data.to_csv(f'../southernoperations/AIID/Processed Faults/{project}-daily-fault.csv', index=False)\n",
    "\n",
    "    print('Fault data transformed and output to \"southernoperations/AIID/Processed Faults\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Fault Metric Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated 14 files and saved to ../southernoperations/AIID/daily_turbine_fault.csv\n",
      "Concatenated 15 files and saved to ../southernoperations/AIID/downtime_lost_energy.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = '../southernoperations/AIID/Processed Faults/'\n",
    "search_strings = ['daily-fault.csv','downtime_lost_energy.csv']\n",
    "output_file_names = ['../southernoperations/AIID/daily_turbine_fault.csv','../southernoperations/AIID/downtime_lost_energy.csv']\n",
    "\n",
    "for i, search_str in enumerate(search_strings):\n",
    "    output_file_name = output_file_names[i]\n",
    "    \n",
    "    # Get all files in the directory\n",
    "    all_files = os.listdir(directory_path)\n",
    "\n",
    "    # Filter files that contain the words 'downtime_lost_energy.csv'\n",
    "    filtered_files = [f for f in all_files if search_str in  f]\n",
    "\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Read and store each file in the list\n",
    "    for file in filtered_files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        dfs.append(pd.read_csv(file_path))\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Save the concatenated DataFrame to a new file\n",
    "    output_file = output_file_name\n",
    "    combined_df =combined_df.dropna().reset_index()\n",
    "    if \"Unnamed: 0\" in combined_df.columns:\n",
    "        combined_df = combined_df.drop(\"Unnamed: 0\", axis = 1)\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Concatenated {len(filtered_files)} files and saved to {output_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiid-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
